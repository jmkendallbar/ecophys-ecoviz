{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing and Feature Calculation\n",
    "\n",
    "Purpose of the notebook: \n",
    "* Load in processed EDF data and annotated data labels \n",
    "* Check temporal alignment of datasets\n",
    "* Calculate derived signals such as heart rate\n",
    "* Calculate features:\n",
    "  1. EEG features: \n",
    "    * to implement first (minimal list):\n",
    "      * Delta spectral power\n",
    "      * Zero crossings\n",
    "      * Abs total power\n",
    "      * Relative Power in Main Frequency Bands** (for EEG and EOG only): Assessing power distribution across standard EEG frequency bands. \n",
    "      * Aperiodicity?\n",
    "   * Potential additional features:\n",
    "      * **Standard Deviation:** Measuring the variation in the EEG signal.\n",
    "      * **Interquartile Range:** Highlighting the spread of the EEG data.\n",
    "      * **Skewness and Kurtosis:** Assessing the asymmetry and tailedness of the EEG signal distribution.\n",
    "      * **Hjorth Mobility and Complexity:** Calculating the frequency and complexity of the signal.\n",
    "      * **Absolute Total Power** in the 0.4-30 Hz Band: Measuring the overall signal power within this frequency range.\n",
    "      * **Relative Power in Main Frequency Bands** (for EEG and EOG only): Assessing power distribution across standard EEG frequency bands. \n",
    "      * **Power Ratios** (e.g., Delta/Beta): Comparing the power in different frequency bands.\n",
    "          * This is especially important for generalizing to other species\n",
    "      * **Permutation Entropy:** Estimating the complexity of the signal.\n",
    "      * **Higuchi and Petrosian Fractal Dimension:** Analyzing the fractal characteristics of the EEG signal.\n",
    "  2. Heart rate (calculated from ECG) features: \n",
    "    * to implement first (minimal list):\n",
    "      * **Mean:** mean HR across epoch\n",
    "      * **Standard deviation:** SD of HR across epoch\n",
    "      * **VLF Power (0-0.001 Hz HR variability)**: Very low frequency (0-0.001 Hz) power\n",
    "      * **SD of VLF Power:** SD of VLF power across epoch\n",
    "    * Potential additional features:\n",
    "      * Time-Domain Features:\n",
    "        * **RR Intervals and their Variations:** The basic measure of HRV, representing the time intervals between successive heartbeats.\n",
    "        * **SDNN (Standard Deviation of NN Intervals):** Measures the variability in heart rate.\n",
    "        * **RMSSD (Root Mean Square of the Successive Differences):** Reflects the short-term components of HRV, particularly influenced by parasympathetic activity.\n",
    "        * **NN50 and pNN50:** NN50 counts the number of pairs of successive NN intervals that differ by more than 50 ms, and pNN50 is the proportion of NN50 divided by the total number of NN intervals.\n",
    "      * Frequency-Domain Features:\n",
    "        * **Power in Different Frequency Bands:** Typically, the power in the Low Frequency (LF, 0.04–0.15 Hz) and High Frequency (HF, 0.15–0.4 Hz) bands are used. LF reflects both sympathetic and parasympathetic activity, while HF is associated with parasympathetic activity.\n",
    "        * **LF/HF Ratio:** Represents the balance between sympathetic and parasympathetic activity.\n",
    "      * Nonlinear Features:\n",
    "        * **Sample Entropy:** Measures the complexity or irregularity of the RR interval time series.\n",
    "        * **Poincaré Plot Parameters:** Such as SD1 (standard deviation of points perpendicular to the line of identity) and SD2 (standard deviation of points along the line of identity), reflecting short-term and long-term HRV respectively.\n",
    "      * Geometrical Features:\n",
    "        * **HRV Triangular Index:** Measures the total number of all NN intervals divided by the height of the histogram of all NN intervals.\n",
    "        * **TINN (Triangular Interpolation of NN Interval Histogram):** Reflects the baseline width of the RR interval distribution.\n",
    "      * Statistical and Miscellaneous Features:\n",
    "        * **Skewness and Kurtosis of RR Intervals:** Indicating the asymmetry and tailedness of the RR interval distribution.\n",
    "        * **Mean/SD Heart Rate:** Average rate of heartbeats per minute.\n",
    "\n",
    "## Load data and dependencies\n",
    "\n",
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Data loading](#data_loading)\n",
    "## [ECG Processing](#ecg_processing)\n",
    "# [Feature extraction](#feature_extraction)\n",
    "## [EEG Features](#feature_eeg)\n",
    "## [ECG Features](#feature_ecg)\n",
    "\n",
    "### [Frequency Band Exploration](#freq_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yasa\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import glob\n",
    "import six\n",
    "import wfdb\n",
    "import pytz\n",
    "import sklearn\n",
    "import pomegranate\n",
    "import pyedflib\n",
    "import sleepecg\n",
    "import datetime\n",
    "import wfdb.processing\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "#import entropy as ent\n",
    "import seaborn as sns\n",
    "from matplotlib import mlab as mlab\n",
    "from sleepecg import detect_heartbeats\n",
    "import matplotlib.gridspec as gs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src directory to the path\n",
    "current_path = os.getcwd()\n",
    "src_path = os.path.abspath(os.path.join(current_path, '..', 'src'))\n",
    "sys.path.insert(0, src_path) \n",
    "from feature_extraction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_loading'></a>\n",
    "\n",
    "---\n",
    "# Load in data\n",
    "\n",
    "---\n",
    "\n",
    "### Navigate to data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the relative path to the folder containing processed data\n",
    "data_folder_path = os.path.abspath(os.path.join(\"..\", \"data\"))\n",
    "process_data_path = os.path.abspath(os.path.join(\"..\", \"data\", \"01_processed-data\"))\n",
    "print(process_data_path)\n",
    "# Get the current working directory\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Check if the current directory ends with the \"Data\" folder\n",
    "# if not current_path.endswith(\"01_processed-data\"):\n",
    "#     # Change the current working directory to the \"Data\" folder, if not already there\n",
    "#     os.chdir(process_data_path)\n",
    "#     print(f\"Changed directory to: {os.getcwd()}\")\n",
    "# else:\n",
    "#     print(\"Already in the correct data directory.\")\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in header information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the header information to identify channels and their sampling frequencies\n",
    "info = mne.io.read_raw_edf(f'{process_data_path}/test12_Wednesday_05_ALL_PROCESSED.edf',\n",
    "                           preload=False).info\n",
    "\n",
    "# Print the channel information\n",
    "print(info)\n",
    "\n",
    "# Identify channels and their corresponding sampling frequencies\n",
    "channels_info = info['chs']\n",
    "sampling_freq_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in raw data for just day one of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EDF file, excluding the EOGs and EKG channels\n",
    "raw = mne.io.read_raw_edf(f'{process_data_path}/test12_Wednesday_05_DAY1_PROCESSED.edf', preload=True)\n",
    "# raw.resample(100)                      # Downsample the data to 100 Hz\n",
    "# raw.filter(0.1, 40)                    # Apply a bandpass filter from 0.1 to 40 Hz\n",
    "# raw.pick_channels(['C4-A1', 'C3-A2'])  # Select a subset of EEG channels\n",
    "raw # Outputs summary data about file\n",
    "\n",
    "# Inspect Data\n",
    "print(raw.info)\n",
    "print('The channels are:', raw.ch_names)\n",
    "print('The sampling frequency is:', raw.info['sfreq'])\n",
    "\n",
    "# Rename channels (replace spaces if any)\n",
    "channel_renaming_dict = {name: name.replace(' ', '_') for name in raw.ch_names}\n",
    "raw.rename_channels(channel_renaming_dict)\n",
    "print('The channels are:', raw.ch_names)\n",
    "\n",
    "# ['ECG_Raw_Ch1', 'ECG_ICA2', 'LEOG_Pruned_Ch2', 'LEMG_Pruned_Ch4', 'REEG2_Pruned_Ch7', 'LEEG3_Pruned_Ch8', \n",
    "# 'REEG2_Raw_Ch7', 'LEEG3_Raw_Ch8', 'EEG_ICA5', 'pitch', 'roll', 'heading', 'GyrZ', 'MagZ', 'ODBA', 'Pressure']\n",
    "\n",
    "# Assuming 'raw' is your Raw object from MNE\n",
    "channel_types = {}\n",
    "\n",
    "for ch in raw.ch_names:\n",
    "    if ch.startswith('ECG'):\n",
    "        channel_types[ch] = 'ecg'\n",
    "    elif ch.startswith(('LEOG', 'REOG')):\n",
    "        channel_types[ch] = 'eog'\n",
    "    elif ch.startswith(('LEMG', 'REMG')):\n",
    "        channel_types[ch] = 'emg'\n",
    "    elif ch.startswith(('LEEG', 'REEG')):\n",
    "        channel_types[ch] = 'eeg'\n",
    "    elif ch in ['pitch', 'roll', 'heading']:\n",
    "        channel_types[ch] = 'resp'\n",
    "    elif ch in ['GyrZ', 'MagZ', 'ODBA']:\n",
    "        channel_types[ch] = 'syst'\n",
    "    elif ch in ['Pressure']:\n",
    "        channel_types[ch] = 'misc'\n",
    "    elif ch == 'Heart_Rate':\n",
    "        channel_types[ch] = 'bio'\n",
    "\n",
    "# Now set the channel types\n",
    "raw.set_channel_types(channel_types)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get metadata from file\n",
    "\n",
    "Get start time, channel names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['ECG_Raw_Ch1', 'ECG_ICA2', 'LEOG_Pruned_Ch2', 'LEMG_Pruned_Ch4', 'REEG2_Pruned_Ch7',\n",
    "            'LEEG3_Pruned_Ch8', 'REEG2_Raw_Ch7', 'LEEG3_Raw_Ch8', 'EEG_ICA5', 'pitch', 'roll',\n",
    "            'heading', 'GyrZ', 'MagZ', 'ODBA', 'Pressure']\n",
    "#     sns.kdeplot(raw.copy().pick([channel]).get_data()[0,:]).set_title(channel)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Data\n",
    "print(raw.info)\n",
    "print('The channels are:', raw.ch_names)\n",
    "print('The sampling frequency is:', raw.info['sfreq'])\n",
    "\n",
    "# Extract the measurement date (start time) from raw.info\n",
    "start_time = raw.info['meas_date']\n",
    "fs = raw.info['sfreq']\n",
    "\n",
    "# Define the PST timezone\n",
    "pst_timezone = pytz.timezone('America/Los_Angeles')\n",
    "\n",
    "# Convert to datetime object in PST\n",
    "if isinstance(start_time, datetime.datetime):\n",
    "    # If it's already a datetime object, just replace the timezone\n",
    "    recording_start_datetime = start_time.replace(tzinfo=None).astimezone(pst_timezone)\n",
    "elif isinstance(start_time, (int, float)):\n",
    "    # Convert timestamp to datetime in PST\n",
    "    recording_start_datetime = pst_timezone.localize(datetime.datetime.fromtimestamp(start_time))\n",
    "else:\n",
    "    # Handle other formats if necessary\n",
    "    pass\n",
    "\n",
    "# Calculate the recording duration in seconds\n",
    "recording_duration_seconds = len(raw) / fs\n",
    "\n",
    "# Calculate the recording end datetime\n",
    "recording_end_datetime = recording_start_datetime + datetime.timedelta(seconds=recording_duration_seconds)\n",
    "\n",
    "# Calculate duration as a timedelta object\n",
    "duration_timedelta = datetime.timedelta(seconds=recording_duration_seconds)\n",
    "\n",
    "# Create a time index\n",
    "#time_index = pd.date_range(recoring_start_datetime, recording_end_datetime)\n",
    "\n",
    "# Format duration into days, hours, minutes, and seconds\n",
    "days = duration_timedelta.days\n",
    "hours, remainder = divmod(duration_timedelta.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "print('The start time in PST (Los Angeles) is:', recording_start_datetime)\n",
    "print('The end time in PST (Los Angeles) is:', recording_end_datetime)\n",
    "print(f'Duration: {days} days, {hours} hours, {minutes} minutes, {seconds} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ecg_processing'></a>\n",
    "\n",
    "---\n",
    "## ECG Pre-Processing\n",
    "\n",
    "---\n",
    "\n",
    "Performing peak-detection and corrections with `sleepecg` package. \n",
    "\n",
    "Many thanks to Sam Proell's helpful tutorial on the topic:\n",
    "https://www.samproell.io/posts/signal/ecg-library-comparison/\n",
    "\n",
    "### Step 1: Select ECG Channel for Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all channel names that contain \"ECG\"\n",
    "ecg_channels = [ch for ch in raw.info['ch_names'] if 'ECG' in ch]\n",
    "\n",
    "# Help user define which should be used by visualizing each to find the better channel\n",
    "# Define the duration to plot (in seconds)\n",
    "plot_duration = 30\n",
    "\n",
    "# Use the start and end index found in the section above\n",
    "\n",
    "start_index = int(2000 * fs) # halfway throughout the day\n",
    "end_index = start_index + int(plot_duration * fs)\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Offset amount\n",
    "offset = 0.005\n",
    "current_offset = 0  # Start with no offset for the first channel\n",
    "\n",
    "# Plot the first 30 seconds of all ECG channels\n",
    "for idx, channel in enumerate(ecg_channels):\n",
    "    ecg_data = raw.copy().pick([channel]).get_data()[0, start_index:int(start_index + plot_duration*fs)]\n",
    "    time_vector = raw.times[start_index:end_index]\n",
    "    \n",
    "    # Offset the ECG data for visualization\n",
    "    ecg_data_with_offset = ecg_data + (idx * current_offset)\n",
    "    \n",
    "    # Add the ECG data trace for each channel\n",
    "    fig.add_trace(go.Scatter(x=time_vector, y=ecg_data_with_offset, mode='lines', \n",
    "                             name= f'{idx} - {channel}'))\n",
    "\n",
    "    # Increase the offset for the next channel\n",
    "    current_offset += offset\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(title='ECG Channel Comparison',\n",
    "                  xaxis_title='Time (seconds)',\n",
    "                  yaxis_title='Amplitude',\n",
    "                  showlegend=True)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Perform peak-detection\n",
    "\n",
    "Use the channel index in the legend above to select a channel to use for peak detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak-detection\n",
    "\n",
    "# Manually set the index of the channel you want to use for peak detection\n",
    "# INPUT HERE:\n",
    "selected_channel_index = 0  # Replace 0 with the index of the channel you want to use\n",
    "\n",
    "# Now use this index to extract the data for peak detection\n",
    "selected_channel = ecg_channels[selected_channel_index]\n",
    "ecg_data = raw.copy().pick([selected_channel]).get_data()[0]\n",
    "\n",
    "rpeaks = detect_heartbeats(ecg_data, fs) # using sleepecg\n",
    "print(rpeaks[0:10])\n",
    "print(fs)\n",
    "\n",
    "print('Peak detection ran successfully.')\n",
    "\n",
    "rpeaks_corrected = wfdb.processing.correct_peaks(\n",
    "    ecg_data, rpeaks, search_radius=200, smooth_window_size=50, peak_dir=\"up\"\n",
    ")\n",
    "# MIGHT HAVE TO UPDATE search_radius\n",
    "wfdb.plot_items(ecg_data, [rpeaks_corrected])  # styling options omitted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Peak Detection Results\n",
    "\n",
    "Generating a plot at a given timestamp to visualize the results of the ECG peak-detection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start string and parsing\n",
    "start_str = \"10/25/2019 20:30:30\"\n",
    "start_time = datetime.datetime.strptime(start_str, '%m/%d/%Y %H:%M:%S')\n",
    "start_time = pst_timezone.localize(start_time)\n",
    "time_diff = (start_time - recording_start_datetime).total_seconds()\n",
    "\n",
    "duration = 2000 # 33 minutes..? gonna make this a little longer\n",
    "duration = 7200 # 2 hours\n",
    "fs = raw.info['sfreq']  # Sampling frequency\n",
    "\n",
    "# Calculate the starting index\n",
    "start_index = int(fs * time_diff)\n",
    "\n",
    "# Extract a segment starting from start_index\n",
    "end_index = start_index + int(duration * fs)\n",
    "print(start_index, end_index)\n",
    "ecg_segment = ecg_data[start_index:end_index]\n",
    "\n",
    "# Create a time vector for the segment\n",
    "segment_time = [i / fs for i in range(end_index - start_index)]\n",
    "\n",
    "# Calculate R-peaks within the segment's range\n",
    "rpeaks_segment = [rp for rp in rpeaks if start_index <= rp < end_index]\n",
    "rpeaks_segment_time = [(rp - start_index) / fs for rp in rpeaks_segment]\n",
    "rpeaks_segment_amplitudes = [ecg_segment[rp - start_index] for rp in rpeaks_segment]\n",
    "\n",
    "# Calculate the time points for the corrected R-peaks within the segment\n",
    "rpeaks_corrected_segment = [rp for rp in rpeaks_corrected if start_index <= rp < end_index]\n",
    "rpeaks_corrected_segment_time = [(rp - start_index) / fs for rp in rpeaks_corrected_segment]\n",
    "rpeaks_corrected_amplitudes = [ecg_segment[rp - start_index] for rp in rpeaks_corrected_segment]\n",
    "\n",
    "# Calculate heart rates between R-peaks\n",
    "heart_rates = [60 / ((rpeaks_segment[i+1] - rpeaks_segment[i]) / fs) for i in range(len(rpeaks_segment) - 1)]\n",
    "# Create a heart rate array matching the frequency of the ECG trace\n",
    "hr_data = np.zeros_like(ecg_segment)\n",
    "# Assign heart rate values to the intervals between R-peaks\n",
    "for i in range(len(rpeaks_segment) - 1):\n",
    "    start_idx = rpeaks_segment[i] - start_index\n",
    "    end_idx = rpeaks_segment[i+1] - start_index\n",
    "    hr_data[start_idx:end_idx] = heart_rates[i]\n",
    "\n",
    "# Calculate heart rates between R-peaks\n",
    "heart_rates2 = [60 / ((rpeaks_corrected_segment[i+1] - rpeaks_corrected_segment[i]) / fs) for i in range(len(\n",
    "    rpeaks_corrected_segment) - 1)]\n",
    "# Create a heart rate array matching the frequency of the ECG trace\n",
    "hr_data2 = np.zeros_like(ecg_segment)\n",
    "# Assign heart rate values to the intervals between R-peaks\n",
    "for i in range(len(rpeaks_corrected_segment) - 1):\n",
    "    start_idx = rpeaks_corrected_segment[i] - start_index\n",
    "    end_idx = rpeaks_corrected_segment[i+1] - start_index\n",
    "    hr_data2[start_idx:end_idx] = heart_rates2[i]\n",
    "\n",
    "# Create subplots with shared x-axis\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "# Add ECG data trace\n",
    "fig.add_trace(go.Scatter(x=segment_time, y=ecg_segment, mode='lines', name='ECG'), row=1, col=1)\n",
    "\n",
    "# Add original R-peaks as red scatter points\n",
    "fig.add_trace(go.Scatter(x=rpeaks_segment_time, y=rpeaks_segment_amplitudes, mode='markers', name='R-peaks',\n",
    "                         marker=dict(size=10, color='red')), row=1, col=1)\n",
    "\n",
    "# Add corrected R-peaks as orange scatter points\n",
    "fig.add_trace(go.Scatter(x=rpeaks_corrected_segment_time, y=rpeaks_corrected_amplitudes, mode='markers',\n",
    "                         name='Corrected R-peaks', marker=dict(size=10, color='orange')), row=1, col=1)\n",
    "\n",
    "# Add heart rate trace\n",
    "fig.add_trace(go.Scatter(x=segment_time, y=hr_data, mode='lines', name='Heart Rate', line=dict(color='red')),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Add heart rate trace\n",
    "fig.add_trace(go.Scatter(x=segment_time, y=hr_data2, mode='lines', name='Heart Rate', line=dict(color='blue')),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(title=f'ECG Data and Heart Rate ({duration} seconds)',\n",
    "                  xaxis_title='Time (seconds)',\n",
    "                  yaxis_title='Amplitude / Heart Rate',\n",
    "                  showlegend=True)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less fancy: plt.plot(ecg_signal); plt.plot(rpeaks, ecg_signal[rpeaks], \"x\")\n",
    "fig = wfdb.plot_items(\n",
    "    ecg_data,\n",
    "    [rpeaks],\n",
    "    fs=fs,\n",
    "    sig_name=[\"ECG\"],\n",
    "    sig_units=[\"mV\"],\n",
    "    time_units=\"seconds\",\n",
    "    return_fig=True,\n",
    "    ann_style=\"o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate heart rates between R-peaks\n",
    "heart_rates = [60 / ((rpeaks_segment[i+1] - rpeaks_segment[i]) / fs) for i in range(len(rpeaks_segment) - 1)]\n",
    "\n",
    "# Create a heart rate array matching the frequency of the ECG trace\n",
    "hr_data = np.zeros_like(ecg_segment)\n",
    "\n",
    "# Assign heart rate values to the intervals between R-peaks\n",
    "for i in range(len(rpeaks_segment) - 1):\n",
    "    start_idx = rpeaks_segment[i] - start_index\n",
    "    end_idx = rpeaks_segment[i+1] - start_index\n",
    "    hr_data[start_idx:end_idx] = heart_rates[i]\n",
    "\n",
    "# Create subplots with shared x-axis\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "# Add ECG data trace\n",
    "fig.add_trace(go.Scatter(x=segment_time, y=ecg_segment, mode='lines', name='ECG'), row=1, col=1)\n",
    "# Add R-peaks as scatter points\n",
    "fig.add_trace(go.Scatter(x=rpeaks_segment_time, y=rpeaks_segment_amplitudes, mode='markers', name='R-peaks',\n",
    "                         marker=dict(size=10, color='red')), row=1, col=1)\n",
    "\n",
    "# Add heart rate trace\n",
    "fig.add_trace(go.Scatter(x=segment_time, y=hr_data, mode='lines', name='Heart Rate', line=dict(color='blue')),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(title=f'ECG Data and Heart Rate ({duration} seconds)',\n",
    "                  xaxis_title='Time (seconds)',\n",
    "                  yaxis_title='Amplitude / Heart Rate',\n",
    "                  showlegend=True)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_extraction'></a>\n",
    "\n",
    "---\n",
    "# Feature extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EEG features: \n",
    "* to implement first (minimal list):\n",
    "  * Delta spectral power\n",
    "  * Zero crossings\n",
    "  * Abs total power\n",
    "2. Heart rate (calculated from ECG) features: \n",
    "* to implement first (minimal list):\n",
    "  * **Mean:** mean HR across epoch\n",
    "  * **Standard deviation:** SD of HR across epoch\n",
    "  * **VLF Power (0-0.001 Hz HR variability)**: Very low frequency (0-0.001 Hz) power\n",
    "  * **SD of VLF Power:** SD of VLF power across epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_eeg'></a>\n",
    "## EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta spectral power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good resource for spectral decomp:<br>\n",
    "https://github.com/pennmem/PythonBootcamp/blob/master/Day%204%20-%20Spectral%20Decomp.ipynb<br>\n",
    "How fourier transforms work:<br>\n",
    "https://neuraldatascience.io/7-eeg/time_freq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "from IPython.core.display import HTML \n",
    "\n",
    "img_path = '../helpful-figs/' \n",
    "display(Image(filename = img_path + 'slow-wave-1.png', width=800, height=300))\n",
    "display(Image(filename = img_path + 'slow-wave-2.png', width=800, height=300))\n",
    "display(Image(filename = img_path + 'rem.png', width=800, height=300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data = raw.copy().pick(['ECG_Raw_Ch1']).get_data()[0]\n",
    "eeg_data = raw.copy().pick(['EEG_ICA5']).get_data()[0]\n",
    "# If you loaded in the full Wednesday file and not just day 1:\n",
    "# one_day = 500 * 60 * 60 * 24 # 500 data points per second, 60 sec/min, 60 min/hr, 24 hr/day\n",
    "# ecg_data = raw.copy().pick(['ECG_ICA2']).get_data()[0, :one_day]\n",
    "# eeg_data = raw.copy().pick(['EEG_ICA5']).get_data()[0, :one_day]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ecg_data), len(eeg_data), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta_power = get_rolling_band_power_welch(eeg_data, 0, len(eeg_data), freq_range=(0.5, 4), ref_power=1,\n",
    "                                                freq=500, window_sec=30, step_size=1)\n",
    "sns.kdeplot(delta_power) # TODO explore: there are some crazy low negative numbers\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_crossings = get_rolling_zero_crossings(eeg_data, 0, len(eeg_data))\n",
    "sns.kdeplot(zero_crossings)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute total power (and power of each frequency band)\n",
    "(this cell takes a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_BANDS = {\n",
    "    \"delta\": (0.4, 4.0),\n",
    "    \"theta\": (4.0, 8.5),\n",
    "    \"alpha\": (8.5, 11.5),\n",
    "    \"sigma\": (11.5, 15.5),\n",
    "    \"beta\": (15.5, 30)\n",
    "}\n",
    "freq_band_names = list(FREQ_BANDS.keys())\n",
    "freq_band_powers = {}\n",
    "for freq_band in FREQ_BANDS.keys():\n",
    "    print(freq_band)\n",
    "    band_power = get_rolling_band_power_welch(eeg_data, 0, len(eeg_data), freq_range=FREQ_BANDS[freq_band],\n",
    "                                              ref_power=1, freq=500, window_sec=2, step_size=1)\n",
    "    freq_band_powers[freq_band] = band_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_power_dB = get_rolling_band_power_welch(eeg_data, 0, len(eeg_data), freq_range=(0.4, 30),\n",
    "                                            ref_power=1, freq=500, window_sec=2, step_size=1)\n",
    "sns.kdeplot(abs_power_dB) # TODO explore: Has some crazy low values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_ecg'></a>\n",
    "\n",
    "## Heart rate (from ECG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling mean & standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = get_heart_rate(ecg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_mean, hr_std = get_rolling_mean_std(hr_data, 0, len(hr_data))\n",
    "sns.kdeplot(hr_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(hr_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(hr_data) # TODO explore: something is weird about this why is there a value at 30000\n",
    "# DONE - cleaned up heart rate code to fill in wacky outliers with the average of its neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLF Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlf_power = get_rolling_band_power_fourier_sum(ecg_data, 0, len(ecg_data), freq_range=(0, 0.01), window_sec=20,\n",
    "                                         ref_power=1)\n",
    "sns.kdeplot(vlf_power[vlf_power < np.quantile(pd.Series(vlf_power).dropna(), 0.98)]) # drop outliers\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE 8000 for window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SD of VLF Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, vlf_power_std = get_rolling_mean_std(vlf_power, 0, len(vlf_power), window_sec=30)\n",
    "sns.kdeplot(vlf_power_std)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='freq_bands'></a>\n",
    "\n",
    "# Freq bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled data\n",
    "# Path to CSV with scored data\n",
    "file_path = f'{data_folder_path}/02_annotated-data/test12_Wednesday_06_Hypnogram_JKB_1Hz.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "df['R.Time'] = pd.to_datetime(df['R.Time']).dt.tz_localize('America/Los_Angeles')\n",
    "df['Sleep.Code'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time and end_time obtained from LabChart as this section goes through most of the stages of wake/sleep\n",
    "start_time = datetime.datetime(2019, 10, 26, hour=5, minute=30, second=30, tzinfo=pytz.timezone('America/Los_Angeles'))\n",
    "end_time = datetime.datetime(2019, 10, 26, hour=5, minute=45, second=0, tzinfo=pytz.timezone('America/Los_Angeles'))\n",
    "duration = (start_time - end_time).seconds\n",
    "duration_interval = duration * 500\n",
    "start_index = (start_time - recording_start_datetime).seconds * 500\n",
    "end_index = (end_time - recording_start_datetime).seconds * 500\n",
    "\n",
    "labels_start_idx =  df[df['R.Time'] == start_time].index[0]\n",
    "labels_end_idx = df[df['R.Time'] == end_time].index[0]\n",
    "\n",
    "df_test = df.loc[labels_start_idx:labels_end_idx-1]\n",
    "\n",
    "eeg_subset = eeg_data[start_index:end_index]\n",
    "sw1_filter = df_test['Sleep.Num'] == 4\n",
    "sw2_filter = df_test['Sleep.Num'] == 5\n",
    "# sw2_filter = np.array([[x] * 500 for x in sw2_filter]).flatten()\n",
    "rem_filter = df_test['Sleep.Num'] == 7\n",
    "# rem_filter = np.array([[x] * 500 for x in rem_filter]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample EEG data (replace this with your actual EEG data)\n",
    "# Sample EEG data is often represented as a 1D array of voltage values over time\n",
    "# For demonstration purposes, we'll generate a sine wave signal\n",
    "sampling_freq = 500  # Sample frequency in Hz\n",
    "t = np.linspace(0, duration, int(sampling_freq * duration))\n",
    "\n",
    "# Perform FFT\n",
    "fft_result = np.fft.fft(eeg_subset)\n",
    "freqs = np.fft.fftfreq(len(fft_result), 1 / sampling_freq)\n",
    "\n",
    "# Keep only positive frequencies (we're dealing with real-valued signals)\n",
    "positive_freqs = freqs[:len(freqs)//2]\n",
    "power_spectrum = np.abs(fft_result[:len(fft_result)//2]) ** 2\n",
    "\n",
    "# Plot frequency domain power distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "index_of_20hz = np.where(positive_freqs > 20)[0][0]\n",
    "plt.plot(positive_freqs[:index_of_20hz], power_spectrum[:index_of_20hz])\n",
    "plt.ylim([0, 0.1])\n",
    "plt.title('Frequency Domain Power Distribution')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
